{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback Prize Best score 0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_descs = df['full_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text_id', 'full_text', 'cohesion', 'syntax', 'vocabulary',\n",
       "       'phraseology', 'grammar', 'conventions', 'spelling_mistakes',\n",
       "       'contractions', 'symbols', 'unique_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from nltk.stem import PorterStemmer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoModel,AutoTokenizer,DebertaV2ForSequenceClassification,DebertaV2Tokenizer\n",
    "\n",
    "class DebertaGrammerDataset(Dataset):\n",
    "    pos_tag_vocab = ['CC',\n",
    "            'WRB',\n",
    "            'EX',\n",
    "            'MD',\n",
    "            'VBN',\n",
    "            'VBD',\n",
    "            'NNS',\n",
    "            'RBR',\n",
    "            'VBZ',\n",
    "            'PRP$',\n",
    "            'VB',\n",
    "            'RP',\n",
    "            'WP',\n",
    "            'VBP',\n",
    "            'JJR',\n",
    "            'VBG',\n",
    "            'PDT',\n",
    "            'JJ',\n",
    "            'JJS',\n",
    "            'WDT',\n",
    "            'IN',\n",
    "            'DT',\n",
    "            'RB',\n",
    "            'NN',\n",
    "            'PRP',\n",
    "            'TO']\n",
    "    stemmer = PorterStemmer()\n",
    "    def __init__(self, data):\n",
    "        '''\n",
    "        Dataset object for base model\n",
    "        :param data:\n",
    "        '''\n",
    "        #self.tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "        data['full_text'] = data[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), '', regex=True)\n",
    "        \n",
    "        self.inputs_ids,self.token_types_ids,self.attention_mask, self.pos_tag = self.clean_text(data['full_text'])\n",
    "        self.cohesion = np.array(data['cohesion'])\n",
    "        self.syntax = np.array(data['syntax'])\n",
    "        self.vocab = np.array((data['vocabulary']))\n",
    "        self.phraseology = np.array(data['phraseology'])\n",
    "        self.grammer = np.array(data['grammar'])\n",
    "        self.conventions = np.array(data['conventions'])\n",
    "        \n",
    "        self.spelling_mistakes = np.array(data['spelling_mistakes'])\n",
    "        self.contractions = np.array(data['contractions'])\n",
    "        self.symbols = np.array(data['symbols'])\n",
    "        self.unique_words = np.array(data['unique_words'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.syntax)\n",
    "    \n",
    "    def feature_transformation(self, vals):\n",
    "        self.mapping = {1:0,1.5:1,2:2,2.5:3,3:4,3.5:5,4:6,4.5:7,5:8}\n",
    "        newl = []\n",
    "        for v in vals:\n",
    "            newl.append(self.mapping[v])\n",
    "        return newl\n",
    "    \n",
    "\n",
    "    def count_pos_tag(self,text):\n",
    "        tag_dict = {}\n",
    "        pos = nltk.pos_tag(text)\n",
    "        tag_types = [item[1] for item in pos]\n",
    "        return tag_types\n",
    "    \n",
    "    def tokenize(self,text,padding=1024):\n",
    "        tokens = self.tokenizer(text,padding=True, truncation=True)\n",
    "        if len(tokens['input_ids']) < padding:\n",
    "            chars_to_add = int(padding-len(tokens['input_ids']))\n",
    "            for i in range(chars_to_add):\n",
    "                tokens['input_ids'].append(0)\n",
    "        else:\n",
    "            tokens['input_ids'] = tokens['input_ids'][:padding]\n",
    "        \n",
    "#         if len(tokens['token_type_ids']) < padding:\n",
    "#             chars_to_add = int(padding-len(tokens['token_type_ids']))\n",
    "#             for i in range(chars_to_add):\n",
    "#                 tokens['token_type_ids'].append(0)\n",
    "#         else:\n",
    "#             tokens['token_type_ids'] = tokens['token_type_ids'][:padding]\n",
    "            \n",
    "            \n",
    "        if len(tokens['attention_mask']) < padding:\n",
    "            chars_to_add = int(padding-len(tokens['attention_mask']))\n",
    "            for i in range(chars_to_add):\n",
    "                tokens['attention_mask'].append(0)\n",
    "        else:\n",
    "            tokens['attention_mask'] = tokens['attention_mask'][:padding]\n",
    "        return tokens\n",
    "    \n",
    "    def sentence_embds(self,text):\n",
    "        embeddings = self.model.encode(text)\n",
    "        return embeddings\n",
    "    \n",
    "    def clean_sentence(self,text):\n",
    "        text = ''.join([i for i in text if not i.isdigit()])\n",
    "        text = re.sub(r'(!|.)1+', '', text) \n",
    "        text = contractions.fix(text)\n",
    "        text = self.stemmer.stem(text)\n",
    "        return text\n",
    "        \n",
    "    def clean_text(self,all_text):\n",
    "        inputs_ids = []\n",
    "        token_type_ids = []\n",
    "        attention_mask = []\n",
    "        sentence_embds = []\n",
    "        pos_tag = []\n",
    "        #all_text = all_text.split(\"\\n\")\n",
    "        for text in all_text:\n",
    "            text = self.clean_sentence(text)\n",
    "            text = text.strip()\n",
    "            #tokens = self.tokenize(text)\n",
    "            inputs_ids.append(text)\n",
    "            token_type_ids.append(0)\n",
    "            attention_mask.append(0)\n",
    "            pos_sentence = self.count_pos_tag(text.split())\n",
    "            pos_tag.append(pos_sentence)\n",
    "            \n",
    "            \n",
    "        return np.array(inputs_ids),np.array(token_type_ids),np.array(attention_mask), np.array(pos_tag)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs_ids[idx],self.token_types_ids[idx],self.attention_mask[idx],self.cohesion[idx],self.syntax[idx],self.vocab[idx],self.phraseology[idx],self.grammer[idx],self.conventions[idx],self.pos_tag[idx],self.spelling_mistakes[idx],self.contractions[idx],self.symbols[idx],self.unique_words[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class MCRMSELoss(nn.Module):\n",
    "    def __init__(self, num_scored=6):\n",
    "        super().__init__()\n",
    "        self.rmse = RMSELoss()\n",
    "        self.num_scored = num_scored\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        score = 0\n",
    "        for i in range(self.num_scored):\n",
    "            score += self.rmse(yhat[:, i], y[:,i]) / self.num_scored\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        classifier_dropout = 0.1\n",
    "        self.dense = [nn.Linear(config.hidden_size, 128), nn.Tanh(), nn.Dropout(classifier_dropout), nn.Linear(128, 32),nn.Tanh(), nn.Dropout(classifier_dropout),\n",
    "                      nn.Linear(32, config.num_labels)]\n",
    "        self.dense = nn.Sequential(*self.dense)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features[:, 0, :]  # take <s> token (equiv. to [CLS])\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "#         x = torch.tanh(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaPreTrainedModel,DebertaV2Model\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "    \n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.deberta = DebertaV2Model.from_pretrained(\"microsoft/deberta-v3-base\") #RobertaModel(config, add_pooling_layer=False)\n",
    "        #self.classifier = RobertaClassificationHead(config)\n",
    "        self.average_pooling = MeanPooling()\n",
    "        \n",
    "        self.num_neurons = 768\n",
    "        self.fc_hidden = 64\n",
    "        self.hidden_size = 32\n",
    "        dropout = 0.1\n",
    "        self.labels = ['cohesion','syntax','vocabulary','phraseology','grammar','conventions']\n",
    "        self.featurs_nn = []\n",
    "        self.cohesion_nn =  nn.Sequential(*[nn.Linear(self.num_neurons, self.fc_hidden), nn.ReLU(inplace=True), nn.Linear(self.fc_hidden, self.hidden_size), nn.ReLU(inplace=True),\n",
    "                  nn.Linear(self.hidden_size, self.hidden_size), nn.ReLU(inplace=True), nn.Linear(self.hidden_size, 1)])\n",
    "        \n",
    "        self.syntax_nn =  nn.Sequential(*[nn.Linear(self.num_neurons, self.fc_hidden), nn.ReLU(inplace=True), nn.Linear(self.fc_hidden, self.hidden_size), nn.ReLU(inplace=True),\n",
    "                  nn.Linear(self.hidden_size, 1)])\n",
    "        \n",
    "        \n",
    "        self.vocabulary_nn =  nn.Sequential(*[nn.Linear(self.num_neurons, self.fc_hidden), nn.ReLU(inplace=True), nn.Linear(self.fc_hidden, self.hidden_size), nn.ReLU(inplace=True),\n",
    "                  nn.Linear(self.hidden_size, 1)])\n",
    "        \n",
    "        self.phraseology_nn =  nn.Sequential(*[nn.Linear(self.num_neurons, self.fc_hidden), nn.ReLU(inplace=True), nn.Linear(self.fc_hidden, self.hidden_size), nn.ReLU(inplace=True),\n",
    "                  nn.Linear(self.hidden_size, 1)])\n",
    "        \n",
    "        self.grammar_nn =  nn.Sequential(*[nn.Linear(self.num_neurons, self.fc_hidden), nn.ReLU(inplace=True), nn.Linear(self.fc_hidden, self.hidden_size), nn.ReLU(inplace=True),\n",
    "                  nn.Linear(self.hidden_size, 1)])\n",
    "        \n",
    "        self.conventions_nn =  nn.Sequential(*[nn.Linear(self.num_neurons, self.fc_hidden), nn.ReLU(inplace=True), nn.Linear(self.fc_hidden, self.hidden_size), nn.ReLU(inplace=True),\n",
    "                  nn.Linear(self.hidden_size, 1)])\n",
    "        \n",
    "        self.features_nn = [self.cohesion_nn, self.syntax_nn, self.vocabulary_nn, self.phraseology_nn, self.grammar_nn,self.conventions_nn]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        spelling_mistakes = None,\n",
    "        contractions = None,\n",
    "        symbols = None,\n",
    "        unique = None\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        outputs = self.deberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,output_hidden_states=True)\n",
    "\n",
    "        \n",
    "        pooling = self.average_pooling(outputs.last_hidden_state,attention_mask)\n",
    "\n",
    "        \n",
    "        output_dict = {}\n",
    "        for f_nn, feature in zip(self.features_nn,self.labels):\n",
    "            newh = pooling.clone()\n",
    "            #newh = torch.cat((newh,spelling_mistakes,contractions,symbols,unique),dim=1)\n",
    "            out = f_nn(newh)\n",
    "            output_dict[feature] = out\n",
    "            \n",
    "        logits = torch.stack((output_dict['cohesion'],output_dict['syntax'],output_dict['vocabulary'],output_dict['phraseology'],output_dict['grammar'],output_dict['conventions']),dim=1)\n",
    "        #logits = self.classifier(sequence_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.SmoothL1Loss()\n",
    "            logits = torch.squeeze(logits,-1)\n",
    "            \n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    inputs_ids, token_types_ids,attention_mask, cohesion, syntax,vocab,phraseology,grammer,conventions,pos_tag = [],[],[],[],[],[],[],[],[],[]\n",
    "    spelling_mistakes,contractions,symbols,unique_words = [],[],[],[]\n",
    "    for data in batch:\n",
    "        inputs_ids.append(data[0])\n",
    "        token_types_ids.append(data[1])\n",
    "        attention_mask.append(data[2])\n",
    "        cohesion.append(data[3])\n",
    "        syntax.append(data[4])\n",
    "        vocab.append(data[5])\n",
    "        phraseology.append(data[6])\n",
    "        grammer.append(data[7])\n",
    "        conventions.append(data[8])\n",
    "        pos_tag.append(data[9])\n",
    "        spelling_mistakes.append(data[10])\n",
    "        contractions.append(data[11])\n",
    "        symbols.append(data[12])\n",
    "        unique_words.append(data[13])\n",
    "        \n",
    "    # self.self.spelling_mistakes[idx],self.self.contractions[idx],self.symbols[idx],self.unique_words[idx]\n",
    "    cohesion = torch.tensor(cohesion, dtype=torch.int64)\n",
    "    syntax = torch.tensor(syntax, dtype=torch.int64)\n",
    "    vocab = torch.tensor(vocab, dtype=torch.int64)\n",
    "    phraseology = torch.tensor(phraseology, dtype=torch.int64)\n",
    "    grammer = torch.tensor(grammer, dtype=torch.int64)\n",
    "    conventions = torch.tensor(conventions, dtype=torch.int64)\n",
    "    pos_tag_vals = pos_tag #torch.tensor(pos_tag, dtype=torch.int64)\n",
    "    #inputs_ids = torch.tensor(inputs_ids, dtype=torch.int64)\n",
    "    token_types_ids = torch.tensor(token_types_ids, dtype=torch.int64)\n",
    "    attention_mask = torch.tensor(attention_mask, dtype=torch.int64)\n",
    "    spelling_mistakes = torch.tensor(spelling_mistakes, dtype=torch.int64)\n",
    "    contractions = torch.tensor(contractions, dtype=torch.int64)\n",
    "    symbols = torch.tensor(symbols, dtype=torch.int64)\n",
    "    unique_words = torch.tensor(unique_words, dtype=torch.int64)\n",
    "    #sentence_embds =  torch.tensor(sentence_embds, dtype=torch.int64)\n",
    "    return inputs_ids,token_types_ids.to(device),attention_mask.to(device), cohesion.to(device), syntax.to(device),vocab.to(device), phraseology.to(device),grammer.to(device), conventions.to(device),pos_tag_vals,spelling_mistakes.to(device),contractions.to(device),symbols.to(device),unique_words.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:138: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "train=df.sample(frac=0.95,random_state=444) #random state is a seed value\n",
    "test=df.drop(train.index)\n",
    "train_dataset = DebertaGrammerDataset(train)\n",
    "valid_dataset = DebertaGrammerDataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset,batch_size=8, shuffle=True,collate_fn=collate_batch,pin_memory=False)\n",
    "valid_loader = DataLoader(valid_dataset,batch_size=8, shuffle=True,collate_fn=collate_batch,pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NewModel(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (average_pooling): MeanPooling()\n",
       "  (cohesion_nn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (syntax_nn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (vocabulary_nn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (phraseology_nn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (grammar_nn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (conventions_nn): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel,AutoTokenizer,DebertaV2ForSequenceClassification,DebertaV2Tokenizer\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n",
    "model = NewModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale, dtype=query_layer.dtype\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss  0.44948378754779694\n",
      "Validation loss:  0.1645028129220009\n",
      "Epoch 1\n",
      "Train loss  0.14573077861374864\n",
      "Validation loss:  0.14986733272671698\n",
      "Epoch 2\n",
      "Train loss  0.12120268951791029\n",
      "Validation loss:  0.15482176393270491\n",
      "Epoch 3\n",
      "Train loss  0.10183356985605012\n",
      "Best model saved,  0.1541392095386982\n",
      "Validation loss:  0.1541392095386982\n",
      "Epoch 4\n",
      "Train loss  0.09001581081344436\n",
      "Validation loss:  0.15493054166436196\n",
      "Epoch 5\n",
      "Train loss  0.08317777843525012\n",
      "Best model saved,  0.15068233981728554\n",
      "Validation loss:  0.15068233981728554\n",
      "Epoch 6\n",
      "Train loss  0.0761432715303575\n",
      "Best model saved,  0.15060335770249367\n",
      "Validation loss:  0.15060335770249367\n",
      "Epoch 7\n",
      "Train loss  0.06896869397411744\n",
      "Validation loss:  0.15297766104340554\n",
      "Epoch 8\n",
      "Train loss  0.06380152289445201\n",
      "Validation loss:  0.16083695888519287\n",
      "Epoch 9\n",
      "Train loss  0.05563814801474412\n",
      "Validation loss:  0.15992644503712655\n",
      "Epoch 10\n",
      "Train loss  0.04799817546348398\n",
      "Validation loss:  0.1672554597258568\n",
      "Epoch 11\n",
      "Train loss  0.03978809505448832\n",
      "Validation loss:  0.1637396588921547\n",
      "Epoch 12\n",
      "Train loss  0.03245371636003256\n",
      "Validation loss:  0.1735733613371849\n",
      "Epoch 13\n",
      "Train loss  0.025561960973815682\n",
      "Validation loss:  0.16668964996933938\n",
      "Epoch 14\n",
      "Train loss  0.01981972503126599\n",
      "Validation loss:  0.17018004283308982\n",
      "Epoch 15\n",
      "Train loss  0.01484185045119375\n",
      "Validation loss:  0.17304338216781617\n",
      "Epoch 16\n",
      "Train loss  0.012179509854953115\n",
      "Validation loss:  0.16653705313801764\n",
      "Epoch 17\n",
      "Train loss  0.013646921692028021\n",
      "Validation loss:  0.18197813481092454\n",
      "Epoch 18\n",
      "Train loss  0.010042128637239026\n",
      "Validation loss:  0.1652373641729355\n",
      "Epoch 19\n",
      "Train loss  0.007051434670089899\n",
      "Validation loss:  0.1788143754005432\n",
      "Epoch 20\n",
      "Train loss  0.005884248331130948\n",
      "Validation loss:  0.16968040466308593\n",
      "Epoch 21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1184/3585464035.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minput_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcohesion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msyntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphraseology\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrammer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconventions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspelling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontractions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0munique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mgt_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcohesion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msyntax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphraseology\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrammer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconventions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2482\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2484\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2486\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2585\u001b[0m                 \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2586\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2587\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2588\u001b[0m             )\n\u001b[1;32m   2589\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2776\u001b[0m             \u001b[0mreturn_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2777\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2778\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2779\u001b[0m         )\n\u001b[1;32m   2780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_or_pair_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mfirst_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mget_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m                 \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0mno_split_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_no_split_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens_trie\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;31m# [\"This is something\", \"<special_token_1>\", \"  else\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# In this case, we already have partial matches (But unfinished)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrie_pointer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrie_pointer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0;31m# This is a final match, we need to reset and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_epochs = 100\n",
    "save_path = 'test/deberta_v3.pth'\n",
    "lr = 4.5e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "best_valid_loss = 999\n",
    "for epoch in range(max_epochs):\n",
    "    all_losses = [] \n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    for batch_idx, batch_data in enumerate(train_loader):\n",
    "        input_idx,input_tokens,input_attention,cohesion,syntax,vocab,phraseology,grammer,conventions,pos_tag,spelling,contractions,symbols,unique = batch_data\n",
    "        input_tensor = tokenizer(input_idx,return_tensors=\"pt\",padding=True, truncation=True, max_length=1024)\n",
    "        input_tensor.to(device)\n",
    "        gt_format = torch.stack((cohesion,syntax,vocab,phraseology,grammer,conventions),dim=1)\n",
    "        gt_format = gt_format.to(torch.float32)\n",
    "        gt_format.to(device)\n",
    "        input_tensor['labels'] = gt_format\n",
    "\n",
    "        \n",
    "        \n",
    "        output = model(**input_tensor)\n",
    "        logits = output.logits\n",
    "        loss = output.loss\n",
    "        \n",
    "        all_losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Train loss \", np.mean(all_losses))\n",
    "    lr *= 0.9 \n",
    "    valid_loss = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(valid_loader):\n",
    "            input_idx,input_tokens,input_attention,cohesion,syntax,vocab,phraseology,grammer,conventions,pos_tag,spelling,contractions,symbols,unique = batch_data\n",
    "            input_tensor = tokenizer(input_idx,return_tensors=\"pt\",padding=True, truncation=True,max_length=1024)\n",
    "            input_tensor.to(device)\n",
    "            gt_format = torch.stack((cohesion,syntax,vocab,phraseology,grammer,conventions),dim=1)\n",
    "            gt_format = gt_format.to(torch.float32)\n",
    "            gt_format.to(device)\n",
    "            input_tensor['labels'] = gt_format\n",
    "\n",
    "            output = model(**input_tensor)\n",
    "            logits = output.logits\n",
    "            loss = output.loss\n",
    "            valid_loss.append(loss.item())\n",
    "              \n",
    "    avg_valid_loss =np.mean(valid_loss)\n",
    "    if epoch > 1: \n",
    "        if avg_valid_loss < best_valid_loss:\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            best_valid_loss = avg_valid_loss\n",
    "            print(\"Best model saved, \", avg_valid_loss)\n",
    "    print(\"Validation loss: \", avg_valid_loss)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "import re\n",
    "import contractions\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from nltk.stem import PorterStemmer\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from transformers import AutoModel,AutoTokenizer,DebertaV2ForSequenceClassification,DebertaV2Tokenizer\n",
    "\n",
    "class DebertaGrammerTestDataset(Dataset):\n",
    "    pos_tag_vocab = ['CC',\n",
    "            'WRB',\n",
    "            'EX',\n",
    "            'MD',\n",
    "            'VBN',\n",
    "            'VBD',\n",
    "            'NNS',\n",
    "            'RBR',\n",
    "            'VBZ',\n",
    "            'PRP$',\n",
    "            'VB',\n",
    "            'RP',\n",
    "            'WP',\n",
    "            'VBP',\n",
    "            'JJR',\n",
    "            'VBG',\n",
    "            'PDT',\n",
    "            'JJ',\n",
    "            'JJS',\n",
    "            'WDT',\n",
    "            'IN',\n",
    "            'DT',\n",
    "            'RB',\n",
    "            'NN',\n",
    "            'PRP',\n",
    "            'TO']\n",
    "    stemmer = PorterStemmer()\n",
    "    def __init__(self, data):\n",
    "        '''\n",
    "        Dataset object for base model\n",
    "        :param data:\n",
    "        '''\n",
    "        self.tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v3-small\")\n",
    "        data['full_text'] = data[\"full_text\"].replace(re.compile(r'[\\n\\r\\t]'), '', regex=True)\n",
    "        \n",
    "        self.inputs_ids,self.token_types_ids,self.attention_mask, self.pos_tag = self.clean_text(data['full_text'])\n",
    "        self.text_ids = data['text_id']\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_ids)\n",
    "    \n",
    "\n",
    "    def count_pos_tag(self,text):\n",
    "        tag_dict = {}\n",
    "        pos = nltk.pos_tag(text)\n",
    "        tag_types = [item[1] for item in pos]\n",
    "        return tag_types\n",
    "    \n",
    "    def tokenize(self,text,padding=1024):\n",
    "        tokens = self.tokenizer(text,padding=True, truncation=True)\n",
    "        if len(tokens['input_ids']) < padding:\n",
    "            chars_to_add = int(padding-len(tokens['input_ids']))\n",
    "            for i in range(chars_to_add):\n",
    "                tokens['input_ids'].append(0)\n",
    "        else:\n",
    "            tokens['input_ids'] = tokens['input_ids'][:padding]\n",
    "        \n",
    "#         if len(tokens['token_type_ids']) < padding:\n",
    "#             chars_to_add = int(padding-len(tokens['token_type_ids']))\n",
    "#             for i in range(chars_to_add):\n",
    "#                 tokens['token_type_ids'].append(0)\n",
    "#         else:\n",
    "#             tokens['token_type_ids'] = tokens['token_type_ids'][:padding]\n",
    "            \n",
    "            \n",
    "        if len(tokens['attention_mask']) < padding:\n",
    "            chars_to_add = int(padding-len(tokens['attention_mask']))\n",
    "            for i in range(chars_to_add):\n",
    "                tokens['attention_mask'].append(0)\n",
    "        else:\n",
    "            tokens['attention_mask'] = tokens['attention_mask'][:padding]\n",
    "        return tokens\n",
    "    \n",
    "    def sentence_embds(self,text):\n",
    "        embeddings = self.model.encode(text)\n",
    "        return embeddings\n",
    "    \n",
    "    def clean_sentence(self,text):\n",
    "        text = ''.join([i for i in text if not i.isdigit()])\n",
    "        text = re.sub(r'(!|.)1+', '', text) \n",
    "        text = contractions.fix(text)\n",
    "        text = self.stemmer.stem(text)\n",
    "        return text\n",
    "        \n",
    "    def clean_text(self,all_text):\n",
    "        inputs_ids = []\n",
    "        token_type_ids = []\n",
    "        attention_mask = []\n",
    "        sentence_embds = []\n",
    "        pos_tag = []\n",
    "        #all_text = all_text.split(\"\\n\")\n",
    "        for text in all_text:\n",
    "            text = self.clean_sentence(text)\n",
    "            text = text.strip()\n",
    "            #tokens = self.tokenize(text)\n",
    "            inputs_ids.append(text)\n",
    "            token_type_ids.append(0)\n",
    "            attention_mask.append(0)\n",
    "            pos_sentence = self.count_pos_tag(text.split())\n",
    "            pos_tag.append(pos_sentence)\n",
    "            \n",
    "            \n",
    "        return np.array(inputs_ids),np.array(token_type_ids),np.array(attention_mask), np.array(pos_tag)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs_ids[idx],self.text_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  self.inputs_ids[idx],self.token_types_ids[idx],self.attention_mask[idx],self.pos_tag[idx],self.text_ids[idx]\n",
    "def collate_test_batch(batch):\n",
    "    text_list,text_length,pos_tag,text_id = [], [],[],[]\n",
    "    for data in batch:\n",
    "        #processed_text = text_pipeline(data[0],1024)\n",
    "        text_list.append(data[0])\n",
    "        text_id.append(data[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "    #text_length = torch.tensor(text_length, dtype=torch.int64)\n",
    "    #text_list = torch.tensor(text_list, dtype=torch.int64)\n",
    "    #pos_tag = torch.tensor(pos_tag, dtype=torch.int64)\n",
    "    return text_list,text_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:117: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "testdf = pd.read_csv('test.csv')\n",
    "test_dataset = DebertaGrammerTestDataset(testdf)\n",
    "test_loader = DataLoader(test_dataset,batch_size=1, shuffle=False,collate_fn=collate_test_batch,pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer,DebertaV2ForSequenceClassification,DebertaV2Tokenizer\n",
    "load_path = 'deberta_v3_last'\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(\"deberta_tokenizer\")\n",
    "# loading model \n",
    "newmodel = NewModel()\n",
    "newmodel.load_state_dict(torch.load(load_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:746: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale, dtype=query_layer.dtype\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
      "/opt/conda/lib/python3.7/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"
     ]
    }
   ],
   "source": [
    "cohs = []\n",
    "syntax = []\n",
    "vocab = [] \n",
    "phraseology = []\n",
    "grammer = []\n",
    "conventions = []\n",
    "text_id = []\n",
    "for batch_idx, batch_data in enumerate(test_loader):\n",
    "        input_idx,text_ids = batch_data\n",
    "        input_tensor = tokenizer(input_idx,return_tensors=\"pt\",padding=True, truncation=True, max_length=1024)\n",
    "        \n",
    "        \n",
    "        output = model(**input_tensor)\n",
    "        logits = output.logits\n",
    "        \n",
    "        logits = logits.tolist()\n",
    "        for i in range(len(logits)):\n",
    "            cohs.append(logits[i][0])\n",
    "            syntax.append(logits[i][1])\n",
    "            vocab.append(logits[i][2])\n",
    "            phraseology.append(logits[i][3])\n",
    "            grammer.append(logits[i][4])\n",
    "            conventions.append(logits[i][5])\n",
    "            text_id.append(text_ids[i])\n",
    "\n",
    "        \n",
    "\n",
    "test_pred = pd.DataFrame()\n",
    "test_pred['text_id'] = [item for item in text_id]\n",
    "test_pred['cohesion'] =[item for item in cohs]\n",
    "test_pred['syntax'] = [item for item in syntax]\n",
    "test_pred['vocabulary'] = [item for item in vocab]\n",
    "test_pred['phraseology'] = [item for item in phraseology]\n",
    "test_pred['grammar'] = [item for item in grammer]\n",
    "test_pred['conventions'] =[item for item in conventions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.940789</td>\n",
       "      <td>2.728086</td>\n",
       "      <td>3.186163</td>\n",
       "      <td>2.850531</td>\n",
       "      <td>2.766949</td>\n",
       "      <td>2.464682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.313389</td>\n",
       "      <td>2.660667</td>\n",
       "      <td>2.692108</td>\n",
       "      <td>1.981151</td>\n",
       "      <td>1.955681</td>\n",
       "      <td>2.404436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.132265</td>\n",
       "      <td>2.958166</td>\n",
       "      <td>3.372356</td>\n",
       "      <td>3.140762</td>\n",
       "      <td>3.108786</td>\n",
       "      <td>3.276099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.940789  2.728086    3.186163     2.850531  2.766949   \n",
       "1  000BAD50D026  2.313389  2.660667    2.692108     1.981151  1.955681   \n",
       "2  00367BB2546B  3.132265  2.958166    3.372356     3.140762  3.108786   \n",
       "\n",
       "   conventions  \n",
       "0     2.464682  \n",
       "1     2.404436  \n",
       "2     3.276099  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
